{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to MacAI's workshop \"Code Your First ML Program\"!\n",
    "In this workshop, we will be taking a look at the \"Breast Cancer Wisconsin\" dataset. This dataset features information on hundreds of images of tumour samples, and their corresponding labels indicating whether they are benign (non-cancerous) or malignant (cancerous). Our job is to create a program that can classify new images such as these into either one of the two categories. <br> <br>\n",
    "For more details on this dataset:\n",
    "> [Breast Cancer Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)<br>\n",
    "\n",
    "To explore other datasets:\n",
    "> [List of Available Datasets](https://scikit-learn.org/stable/datasets/index.html)<br><br>\n",
    "\n",
    "### Great, we're ready to begin! Let's start by importing the function to load the dataset. We can important any of the built-in datasets using the following code:\n",
    " > # from sklearn.datasets import d\n",
    "  - The parameter \"d\" takes in a dataset from list of ***sklearn*** datasets. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll actually load the dataset and store it in a variable using the following code:\n",
    "> # ourData = load_datasetName()\n",
    " - The parameter \"datasetname\" takes in the name of your sklearn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bc = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we can proceed, we must understand what information is in our dataset. The image below offers a visual representation of this data in the context of ***sklearn***:\n",
    "\n",
    "![alt text](ExampleImage.png \"Title\")\n",
    "\n",
    "Conceptually, our ML model/algorithm is observing training data, trying to establish patterns in its **features**, and then using these patterns to predict **labels**. Fundamentally, however, our algorithm must operate in the context of numbers. For example, if we plug our data into a function, it has no way of outputting \"dog\" as its classification. Instead, it may output 0's and 1's, where \"dog\" is represented by 0, and \"cat\" is represented by 1. The input for our algorithm, therefore, is the **data** contained within our **features**, and the output is the **targets**. To extract meaningful information, we need to know what this **data** and these **targets** really mean. The meaning of these is contained under **feature_names** and **target_names**.<br>\n",
    "### Let's print the feature_names and target_names of our dataset:\n",
    "\n",
    "> # ourData.feature_names\n",
    "> # ourData.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(bc.feature_names)\n",
    "print(bc.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's look at the 0-th datapoint in our dataset, as well as its corresponding target:<br>\n",
    "> # ourData.data[0]<br>\n",
    "> # ourData.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n"
     ]
    }
   ],
   "source": [
    "print(bc.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make this a little easier to see: <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius : 17.99\n",
      "mean texture : 10.38\n",
      "mean perimeter : 122.8\n",
      "mean area : 1001.0\n",
      "mean smoothness : 0.1184\n",
      "mean compactness : 0.2776\n",
      "mean concavity : 0.3001\n",
      "mean concave points : 0.1471\n",
      "mean symmetry : 0.2419\n",
      "mean fractal dimension : 0.07871\n",
      "radius error : 1.095\n",
      "texture error : 0.9053\n",
      "perimeter error : 8.589\n",
      "area error : 153.4\n",
      "smoothness error : 0.006399\n",
      "compactness error : 0.04904\n",
      "concavity error : 0.05373\n",
      "concave points error : 0.01587\n",
      "symmetry error : 0.03003\n",
      "fractal dimension error : 0.006193\n",
      "worst radius : 25.38\n",
      "worst texture : 17.33\n",
      "worst perimeter : 184.6\n",
      "worst area : 2019.0\n",
      "worst smoothness : 0.1622\n",
      "worst compactness : 0.6656\n",
      "worst concavity : 0.7119\n",
      "worst concave points : 0.2654\n",
      "worst symmetry : 0.4601\n",
      "worst fractal dimension : 0.1189\n",
      "0 : malignant\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(bc.feature_names)):\n",
    "    print(bc.feature_names[i], ':', bc.data[0][i])\n",
    "print(bc.target[0], ':', bc.target_names[bc.target[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excellent! We now understand the terms in sklearn, and have explored our data to see what it consists of.\n",
    "\n",
    "### The last step before actually making our classifier is to split our data into training and testing data.\n",
    "Remember, we want our model to *train* on the **features** *and* **labels** of our training data in order to establish patterns. Then, we want it to *predict* the **labels** of our test data using *only* its **features**.\n",
    "\n",
    "### To do this, we'll first import the appropriate function from sklearn:\n",
    "> # from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll now split our data using the following code:\n",
    "> # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = d)\n",
    " - The parameter \"X_train\" corresponds with our training features\n",
    " - The parameter \"X_test\" corresponds with our test features \n",
    " - The parameter \"y_train\" corresponds with our training labels\n",
    " - The parameter \"y_test\" corresponds with our test labels<br><br>\n",
    " - The parameter \"X\" takes in your dataset's **data**\n",
    " - The parameter \"y\" takes in your dataset's **targets**\n",
    " - The parameter \"d\" takes in the desired fraction of data allocated to the test data, as a decimal\n",
    "\n",
    "**Note 1 |** Notice that the \"X\" and \"y\" parameters must be declared before calling this function. <br>\n",
    "**Note 2 |** A common convention is to use uppercase \"X\" and lowercase \"y\".\n",
    "\n",
    "### Let's look at the code below:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = bc.data\n",
    "y = bc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can finally create our classifier! \n",
    "There are a number of different classifiers in ***sklearn***, and the full list can be found here:<br>\n",
    "> [List of sklearn Classifiers](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)<br>\n",
    "\n",
    "In this example, we will use the ***K-Nearest Neighbors*** classifier. More information about the classifier can be found here:\n",
    "> [Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)<br><br>\n",
    "> [Video](https://www.youtube.com/watch?v=MDniRwXizWo)\n",
    "\n",
    "### To begin, we'll import this classifier and initialize it:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we need to \"train\" our classifier using our training data. We use the following code:\n",
    "> # classifier.fit(trainingFeatures, trainingLabels)\n",
    " - \"classifier\" refers to the name of our classifier\n",
    " - The parameter \"trainingFeatures\" refers to our training **data**\n",
    " - The parameter \"trainingLabels\" refers to our training **targets**\n",
    "\n",
    "### Let's look at the code below:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cool, we've just trained our classifier! We won't delve into the interworkings of *how* the algorithm was \"trained\" and the math behind it, but appreciate that our classifier has now established some patterns in our data and is ready to make predicitions. We'll do this with the following code:\n",
    "> # classifier.predict(testFeatures)\n",
    " - Again, \"classifier\" simply refers to the name we've given to our classifier\n",
    " - The parameter \"testFeatures\" refers to our test **data**\n",
    "\n",
    "### We'll make and print these predictions using the code below:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1\n",
      " 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(len(predictions)):\n",
    "   # print(predictions[i], ' = ', bc.target_names[predictions[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweet! We can go back to our dataset and manually check if the predictions are correct, but that would be extremely inefficient, especially for larger datasets. Instead, we'll measure the accuracy of our predictions using an in-built function. We'll first import this, and then call it:\n",
    "> # from sklearn.metrics import accuracy_score\n",
    "> # accuracy_score(testLabels, predictions)\n",
    " - The parameter \"testLabels\" corresponds to the actual test targets from our dataset.\n",
    " - The parameter \"predictions\" corresponds to the targets we jsut predicted for our test features.\n",
    "\n",
    "### Let's look at the code below:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not too bad! If we re-run our entire program, we will observe a slightly different accuracy, but within the same ballpark range. This is due to random variation in the way our algorithm learns and establishes patterns.<br>\n",
    "\n",
    "--- \n",
    "\n",
    "---\n",
    "\n",
    "# Congratulations! You've just created your (potentially) first ML program and  used it to successfully predict whether a tumour is benign or malginant based on its appearance. While solving new real-life problems may not be so trivial, the concepts you've learned here will remain with you throughout your journey in AI.\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
